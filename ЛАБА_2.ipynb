{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gn1dus/mosi/blob/main/%D0%9B%D0%90%D0%91%D0%90_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Классические методы преобразования текста"
      ],
      "metadata": {
        "id": "cHyJgxrNcb2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Установка необходимых библиотек"
      ],
      "metadata": {
        "id": "l0WEQdEWjKaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du8zGZENjBx1",
        "outputId": "2c1599f4-6327-413a-db6f-1b2b5fd713ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy3\n",
            "  Downloading pymorphy3-2.0.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Downloading pymorphy3-2.0.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.3 pymorphy3-dicts-ru-2.4.417150.4580142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импорт библиотек и данных"
      ],
      "metadata": {
        "id": "c59CZC4FcuAx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV5Jes6gOVOV",
        "outputId": "dff3b166-5474-44c5-ad47-1f16a254b686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pymorphy3\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import math\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"Там, за туманом, в горах седых\",\n",
        "        \"Где пещеры темны и стары\",\n",
        "        \"Мы уйдём до первых лучей\",\n",
        "        \"Чтоб вернуть забытые дары.\"\n",
        "\n",
        "        \"Сосны шумели в вышине\",\n",
        "        \"Ветер стонал в ночной тени\",\n",
        "        \"Красный огонь, дрожа, пылал\",\n",
        "        \"Деревья, как факелы, горели в темни.\"  ]"
      ],
      "metadata": {
        "id": "J1YPcpbIkqSw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Применить к текстам лемматизацию, удаления стоп слов и токенизацию по словам"
      ],
      "metadata": {
        "id": "-GOEr5OMlyQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy3.MorphAnalyzer()\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "\n",
        "def preprocessing(texts: list[str]) -> list[list[str]]:\n",
        "  preprocessing_texts = []\n",
        "  for text in texts:\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    lemmatized_words = [\n",
        "      morph.parse(token)[0].normal_form\n",
        "      for token in tokens\n",
        "      if token not in stop_words]\n",
        "\n",
        "    preprocessing_texts.append(lemmatized_words)\n",
        "  return preprocessing_texts"
      ],
      "metadata": {
        "id": "A7l54fOUc7gK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_texts = preprocessing(texts)\n",
        "print(preprocessed_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw3KH-awjyRj",
        "outputId": "ec8b07e6-2088-438b-8b15-2fc9e11b2f3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[',', 'туман', ',', 'гора', 'седой'], ['пещера', 'тёмный', 'старый'], ['уйти', 'первый', 'луч'], ['вернуть', 'забытый', 'дары.сосна', 'шуметь', 'вышина'], ['ветер', 'стонать', 'ночной', 'тень'], ['красный', 'огонь', ',', 'дрожать', ',', 'пылать'], ['дерево', ',', 'факел', ',', 'гореть', 'темнить', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Реализовать Bag of Words"
      ],
      "metadata": {
        "id": "-ZeKvp-jhmNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dict(texts: list[str]) -> dict[str]:\n",
        "  word_freq = {}\n",
        "\n",
        "  for i, words in enumerate(preprocessed_texts):\n",
        "      for word in words:\n",
        "          if word not in word_freq:\n",
        "              word_freq[word] = {}\n",
        "          if f'text_{i}' not in word_freq[word]:\n",
        "              word_freq[word][f'text_{i}'] = 0\n",
        "          word_freq[word][f'text_{i}'] += 1\n",
        "\n",
        "  return word_freq"
      ],
      "metadata": {
        "id": "-vXrdQMxvDpq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BoW = make_dict(texts)\n",
        "print(BoW)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucB5pGIxxrvv",
        "outputId": "1e1228e4-1057-4b77-f51c-7759cd806a5c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{',': {'text_0': 2, 'text_5': 2, 'text_6': 2}, 'туман': {'text_0': 1}, 'гора': {'text_0': 1}, 'седой': {'text_0': 1}, 'пещера': {'text_1': 1}, 'тёмный': {'text_1': 1}, 'старый': {'text_1': 1}, 'уйти': {'text_2': 1}, 'первый': {'text_2': 1}, 'луч': {'text_2': 1}, 'вернуть': {'text_3': 1}, 'забытый': {'text_3': 1}, 'дары.сосна': {'text_3': 1}, 'шуметь': {'text_3': 1}, 'вышина': {'text_3': 1}, 'ветер': {'text_4': 1}, 'стонать': {'text_4': 1}, 'ночной': {'text_4': 1}, 'тень': {'text_4': 1}, 'красный': {'text_5': 1}, 'огонь': {'text_5': 1}, 'дрожать': {'text_5': 1}, 'пылать': {'text_5': 1}, 'дерево': {'text_6': 1}, 'факел': {'text_6': 1}, 'гореть': {'text_6': 1}, 'темнить': {'text_6': 1}, '.': {'text_6': 1}}\n"
          ]
        }
      ]
    }
  ]
}